from __future__ import annotations

import argparse
import json
from collections import defaultdict
from datetime import datetime, timezone
from pathlib import Path

from security_agents.automation import (
    apply_fix_diffs,
    create_multi_prs_for_groups,
    create_pr_for_changes,
    ensure_clean_git_repo,
)
from security_agents.config import load_config
from security_agents.execution import run_validation_execution
from security_agents.pipeline import run_pipeline
from security_agents.selection import (
    SEVERITY_ORDER,
    filter_and_rank_fixes,
    finding_severity,
    summarize_findings_by_class,
)


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(description="Run a detector-manager-validator-fixer security pipeline")
    parser.add_argument("--repo", default=".", help="Path to target repository")
    parser.add_argument("--config", default=None, help="Path to YAML config")
    parser.add_argument("--out", default="security_report.json", help="Output JSON file")
    parser.add_argument(
        "--summary-only",
        action="store_true",
        help="Write only high-level counts and accepted findings (skip rejected/validation/fixes payloads).",
    )
    parser.add_argument(
        "--fail-on-severity",
        choices=["low", "medium", "high", "critical"],
        default=None,
        help="Exit non-zero if any accepted finding is at or above this severity.",
    )
    parser.add_argument(
        "--min-severity",
        choices=["low", "medium", "high", "critical"],
        default="low",
        help="Only include fixes for findings at or above this severity.",
    )
    parser.add_argument(
        "--only-severity",
        choices=["low", "medium", "high", "critical"],
        default=None,
        help="Only include fixes for findings at exactly this severity.",
    )
    parser.add_argument(
        "--min-confidence",
        type=float,
        default=0.0,
        help="Only include fixes for findings with confidence >= this value (0..1).",
    )
    parser.add_argument(
        "--max-fixes",
        type=int,
        default=None,
        help="Maximum number of fixes to apply/create PRs for after filtering and ranking.",
    )
    parser.add_argument(
        "--run-validation",
        action="store_true",
        help="Execute validator-provided test commands against --repo.",
    )
    parser.add_argument(
        "--validation-command-template",
        default=None,
        help="Fallback command template if validator does not provide execution_commands. Supports {id}, {test_file}, {test_name}.",
    )
    parser.add_argument(
        "--validation-timeout-seconds",
        type=int,
        default=120,
        help="Timeout for each validation command.",
    )
    parser.add_argument(
        "--validation-max-items",
        type=int,
        default=20,
        help="Maximum number of validation items to execute.",
    )
    parser.add_argument(
        "--apply-fixes",
        action="store_true",
        help="Attempt to apply generated patch diffs with git apply.",
    )
    parser.add_argument(
        "--allow-dirty-repo",
        action="store_true",
        help="Allow applying fixes in a repo with existing uncommitted changes.",
    )
    parser.add_argument(
        "--create-pr",
        action="store_true",
        help="Create branch, commit, push, and open a PR with applied fixes (requires --apply-fixes).",
    )
    parser.add_argument("--pr-base", default="main", help="Base branch for PR creation.")
    parser.add_argument("--pr-branch", default=None, help="Override PR branch name.")
    parser.add_argument("--pr-title", default="secagent: automated security fixes", help="PR title.")
    parser.add_argument(
        "--pr-body",
        default=(
            "Automated security fixes generated by secagent.\n\n"
            "- Detector/manager triage completed\n"
            "- Validation stage executed where configured\n"
            "- Minimal patch diffs applied automatically\n"
        ),
        help="PR body.",
    )
    parser.add_argument("--pr-draft", action="store_true", help="Open the PR as draft.")
    parser.add_argument(
        "--multi-pr-mode",
        choices=["none", "class", "severity", "class-severity"],
        default="none",
        help="Split fixes into multiple PRs by vulnerability class/severity.",
    )
    parser.add_argument(
        "--multi-pr-limit",
        type=int,
        default=10,
        help="Maximum number of multi-PR groups to create.",
    )
    parser.add_argument(
        "--commit-message",
        default="secagent: apply automated security fixes",
        help="Commit message used for PR flow.",
    )
    return parser.parse_args()


def _build_fix_lookup(accepted_findings: list[dict]) -> dict[str, dict]:
    return {str(item.get("id", "")): item for item in accepted_findings}


def _group_key_for_fix(fix: dict, lookup: dict[str, dict], mode: str) -> str:
    fix_id = str(fix.get("id", ""))
    finding = lookup.get(fix_id, {})
    vuln_class = str(finding.get("vulnerability_class", "unknown-class"))
    severity = finding_severity(finding)
    if mode == "class":
        return vuln_class
    if mode == "severity":
        return severity
    if mode == "class-severity":
        return f"{vuln_class} :: {severity}"
    return "all"


def main() -> int:
    args = parse_args()
    repo = Path(args.repo).resolve()
    config = load_config(args.config)

    if args.min_confidence < 0 or args.min_confidence > 1:
        raise ValueError("--min-confidence must be between 0 and 1")
    if args.max_fixes is not None and args.max_fixes < 0:
        raise ValueError("--max-fixes must be >= 0")

    output = run_pipeline(repo, config)
    generated_at = datetime.now(timezone.utc).isoformat()
    severity_counts = {"low": 0, "medium": 0, "high": 0, "critical": 0}
    for finding in output.accepted_findings:
        severity_counts[finding_severity(finding)] += 1
    class_summary = summarize_findings_by_class(output.accepted_findings)

    validation_execution: list[dict] = []
    selected_fixes = filter_and_rank_fixes(
        accepted_findings=output.accepted_findings,
        fixes=output.fixes,
        min_confidence=args.min_confidence,
        min_severity=args.min_severity,
        only_severity=args.only_severity,
        max_fixes=args.max_fixes,
    )
    filtered_fixes = selected_fixes
    if args.run_validation:
        validation_execution = run_validation_execution(
            repo=repo,
            validation_items=output.validation,
            command_template=args.validation_command_template,
            timeout_seconds=args.validation_timeout_seconds,
            max_items=args.validation_max_items,
        )
        failed_ids = {item.get("id", "") for item in validation_execution if item.get("status") == "failed"}
        if failed_ids:
            filtered_fixes = [fix for fix in selected_fixes if str(fix.get("id", "")) in failed_ids]
        else:
            filtered_fixes = []

    apply_results: list[dict] = []
    pr_result: dict | None = None
    pr_results: list[dict] = []
    if args.create_pr and not args.apply_fixes:
        raise ValueError("--create-pr requires --apply-fixes")
    if args.multi_pr_limit <= 0:
        raise ValueError("--multi-pr-limit must be > 0")

    if args.apply_fixes and not args.create_pr:
        if not args.allow_dirty_repo:
            clean, reason = ensure_clean_git_repo(repo)
            if not clean:
                raise RuntimeError(f"Refusing to apply fixes: {reason}. Use --allow-dirty-repo to override.")
        apply_results = apply_fix_diffs(repo, filtered_fixes)

    if args.create_pr:
        if not filtered_fixes:
            raise RuntimeError("No fixes selected; refusing to create PR.")
        if args.multi_pr_mode == "none":
            pr_result = create_pr_for_changes(
                repo=repo,
                base=args.pr_base,
                branch=args.pr_branch,
                title=args.pr_title,
                body=args.pr_body,
                draft=args.pr_draft,
                commit_message=args.commit_message,
                fixes=filtered_fixes,
            )
            if not pr_result.get("ok"):
                raise RuntimeError(f"PR creation failed: {pr_result.get('error', 'unknown error')}")
            apply_results = list(pr_result.get("apply_results", []))
        else:
            lookup = _build_fix_lookup(output.accepted_findings)
            grouped: dict[str, list[dict]] = defaultdict(list)
            for fix in filtered_fixes:
                grouped[_group_key_for_fix(fix, lookup, args.multi_pr_mode)].append(fix)
            group_items = [
                {"label": label, "fixes": fixes}
                for label, fixes in sorted(grouped.items(), key=lambda pair: pair[0])[: args.multi_pr_limit]
            ]
            if not group_items:
                raise RuntimeError("No fix groups to create PRs for.")
            pr_results = create_multi_prs_for_groups(
                repo=repo,
                base=args.pr_base,
                groups=group_items,
                title_prefix=args.pr_title,
                body_prefix=args.pr_body,
                draft=args.pr_draft,
                commit_message_prefix=args.commit_message,
            )
            if not any(item.get("ok") for item in pr_results):
                raise RuntimeError("Multi-PR creation failed for all groups.")

    payload = {
        "generated_at": generated_at,
        "repo": str(repo),
        "model": config.model,
        "scanned_file_count": len(output.scanned_files),
        "scanned_files": output.scanned_files,
        "severity_counts": severity_counts,
        "class_summary": class_summary,
        "selection": {
            "min_severity": args.min_severity,
            "only_severity": args.only_severity,
            "min_confidence": args.min_confidence,
            "max_fixes": args.max_fixes,
            "selected_fix_count_pre_validation": len(selected_fixes),
        },
        "accepted_findings": output.accepted_findings,
        "rejected_findings": [] if args.summary_only else output.rejected_findings,
        "validation": [] if args.summary_only else output.validation,
        "fixes": [] if args.summary_only else output.fixes,
        "validation_execution": validation_execution,
        "fixes_selected_after_validation": filtered_fixes,
        "fix_application": apply_results,
        "pr": pr_result,
        "prs": pr_results,
    }

    out_path = Path(args.out)
    out_path.write_text(json.dumps(payload, indent=2))

    print(f"Wrote report: {out_path}")
    print(f"Accepted findings: {len(output.accepted_findings)}")
    print(f"Rejected findings: {len(output.rejected_findings)}")
    print(f"Validation items: {len(output.validation)}")
    print(f"Fix plans: {len(output.fixes)}")
    print(f"Fixes selected (pre-validation): {len(selected_fixes)}")
    if args.run_validation:
        print(f"Validation execution items: {len(validation_execution)}")
        print(f"Fixes selected after validation execution: {len(filtered_fixes)}")
    if args.apply_fixes:
        applied_count = sum(1 for item in apply_results if item.get("applied"))
        print(f"Fixes applied: {applied_count}/{len(apply_results)}")
    if pr_result and pr_result.get("ok"):
        print(f"PR created: {pr_result.get('pr_url')}")
    if pr_results:
        created = [item for item in pr_results if item.get("ok")]
        print(f"PRs created: {len(created)}/{len(pr_results)}")
        for item in created:
            print(f"- [{item.get('label')}] {item.get('pr_url')}")
    print(f"Severity counts: {severity_counts}")

    if args.fail_on_severity:
        threshold = SEVERITY_ORDER[args.fail_on_severity]
        has_blocker = any(
            SEVERITY_ORDER[finding_severity(finding)] >= threshold for finding in output.accepted_findings
        )
        if has_blocker:
            print(f"Failing because finding severity meets threshold: {args.fail_on_severity}")
            return 2
    return 0


if __name__ == "__main__":
    raise SystemExit(main())
