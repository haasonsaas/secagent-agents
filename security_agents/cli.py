from __future__ import annotations

import argparse
import json
from datetime import datetime, timezone
from pathlib import Path

from security_agents.automation import apply_fix_diffs, create_pr_for_changes, ensure_clean_git_repo
from security_agents.config import load_config
from security_agents.execution import run_validation_execution
from security_agents.pipeline import run_pipeline


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(description="Run a detector-manager-validator-fixer security pipeline")
    parser.add_argument("--repo", default=".", help="Path to target repository")
    parser.add_argument("--config", default=None, help="Path to YAML config")
    parser.add_argument("--out", default="security_report.json", help="Output JSON file")
    parser.add_argument(
        "--summary-only",
        action="store_true",
        help="Write only high-level counts and accepted findings (skip rejected/validation/fixes payloads).",
    )
    parser.add_argument(
        "--fail-on-severity",
        choices=["low", "medium", "high", "critical"],
        default=None,
        help="Exit non-zero if any accepted finding is at or above this severity.",
    )
    parser.add_argument(
        "--run-validation",
        action="store_true",
        help="Execute validator-provided test commands against --repo.",
    )
    parser.add_argument(
        "--validation-command-template",
        default=None,
        help="Fallback command template if validator does not provide execution_commands. Supports {id}, {test_file}, {test_name}.",
    )
    parser.add_argument(
        "--validation-timeout-seconds",
        type=int,
        default=120,
        help="Timeout for each validation command.",
    )
    parser.add_argument(
        "--validation-max-items",
        type=int,
        default=20,
        help="Maximum number of validation items to execute.",
    )
    parser.add_argument(
        "--apply-fixes",
        action="store_true",
        help="Attempt to apply generated patch diffs with git apply.",
    )
    parser.add_argument(
        "--allow-dirty-repo",
        action="store_true",
        help="Allow applying fixes in a repo with existing uncommitted changes.",
    )
    parser.add_argument(
        "--create-pr",
        action="store_true",
        help="Create branch, commit, push, and open a PR with applied fixes (requires --apply-fixes).",
    )
    parser.add_argument("--pr-base", default="main", help="Base branch for PR creation.")
    parser.add_argument("--pr-branch", default=None, help="Override PR branch name.")
    parser.add_argument("--pr-title", default="secagent: automated security fixes", help="PR title.")
    parser.add_argument(
        "--pr-body",
        default=(
            "Automated security fixes generated by secagent.\n\n"
            "- Detector/manager triage completed\n"
            "- Validation stage executed where configured\n"
            "- Minimal patch diffs applied automatically\n"
        ),
        help="PR body.",
    )
    parser.add_argument("--pr-draft", action="store_true", help="Open the PR as draft.")
    parser.add_argument(
        "--commit-message",
        default="secagent: apply automated security fixes",
        help="Commit message used for PR flow.",
    )
    return parser.parse_args()


SEVERITY_ORDER = {"low": 1, "medium": 2, "high": 3, "critical": 4}


def _finding_severity(finding: dict) -> str:
    explicit = str(finding.get("updated_severity", "")).lower()
    if explicit in SEVERITY_ORDER:
        return explicit
    nested = finding.get("finding", {})
    nested_sev = str(nested.get("severity", "")).lower()
    if nested_sev in SEVERITY_ORDER:
        return nested_sev
    return "low"


def main() -> int:
    args = parse_args()
    repo = Path(args.repo).resolve()
    config = load_config(args.config)

    output = run_pipeline(repo, config)
    generated_at = datetime.now(timezone.utc).isoformat()
    severity_counts = {"low": 0, "medium": 0, "high": 0, "critical": 0}
    for finding in output.accepted_findings:
        severity_counts[_finding_severity(finding)] += 1

    validation_execution: list[dict] = []
    filtered_fixes = output.fixes
    if args.run_validation:
        validation_execution = run_validation_execution(
            repo=repo,
            validation_items=output.validation,
            command_template=args.validation_command_template,
            timeout_seconds=args.validation_timeout_seconds,
            max_items=args.validation_max_items,
        )
        failed_ids = {item.get("id", "") for item in validation_execution if item.get("status") == "failed"}
        if failed_ids:
            filtered_fixes = [fix for fix in output.fixes if str(fix.get("id", "")) in failed_ids]
        else:
            filtered_fixes = []

    apply_results: list[dict] = []
    pr_result: dict | None = None
    if args.create_pr and not args.apply_fixes:
        raise ValueError("--create-pr requires --apply-fixes")

    if args.apply_fixes:
        if not args.allow_dirty_repo:
            clean, reason = ensure_clean_git_repo(repo)
            if not clean:
                raise RuntimeError(f"Refusing to apply fixes: {reason}. Use --allow-dirty-repo to override.")
        apply_results = apply_fix_diffs(repo, filtered_fixes)

    if args.create_pr:
        if not any(item.get("applied") for item in apply_results):
            raise RuntimeError("No fixes were applied; refusing to create PR.")
        pr_result = create_pr_for_changes(
            repo=repo,
            base=args.pr_base,
            branch=args.pr_branch,
            title=args.pr_title,
            body=args.pr_body,
            draft=args.pr_draft,
            commit_message=args.commit_message,
        )
        if not pr_result.get("ok"):
            raise RuntimeError(f"PR creation failed: {pr_result.get('error', 'unknown error')}")

    payload = {
        "generated_at": generated_at,
        "repo": str(repo),
        "model": config.model,
        "scanned_file_count": len(output.scanned_files),
        "scanned_files": output.scanned_files,
        "severity_counts": severity_counts,
        "accepted_findings": output.accepted_findings,
        "rejected_findings": [] if args.summary_only else output.rejected_findings,
        "validation": [] if args.summary_only else output.validation,
        "fixes": [] if args.summary_only else output.fixes,
        "validation_execution": validation_execution,
        "fixes_selected_after_validation": filtered_fixes,
        "fix_application": apply_results,
        "pr": pr_result,
    }

    out_path = Path(args.out)
    out_path.write_text(json.dumps(payload, indent=2))

    print(f"Wrote report: {out_path}")
    print(f"Accepted findings: {len(output.accepted_findings)}")
    print(f"Rejected findings: {len(output.rejected_findings)}")
    print(f"Validation items: {len(output.validation)}")
    print(f"Fix plans: {len(output.fixes)}")
    if args.run_validation:
        print(f"Validation execution items: {len(validation_execution)}")
        print(f"Fixes selected after validation execution: {len(filtered_fixes)}")
    if args.apply_fixes:
        applied_count = sum(1 for item in apply_results if item.get("applied"))
        print(f"Fixes applied: {applied_count}/{len(apply_results)}")
    if pr_result and pr_result.get("ok"):
        print(f"PR created: {pr_result.get('pr_url')}")
    print(f"Severity counts: {severity_counts}")

    if args.fail_on_severity:
        threshold = SEVERITY_ORDER[args.fail_on_severity]
        has_blocker = any(
            SEVERITY_ORDER[_finding_severity(finding)] >= threshold for finding in output.accepted_findings
        )
        if has_blocker:
            print(f"Failing because finding severity meets threshold: {args.fail_on_severity}")
            return 2
    return 0


if __name__ == "__main__":
    raise SystemExit(main())
